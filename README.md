# 📕LLM小组自建数据集指南

## 目录
- [📕LLM小组自建数据集指南](#llm小组自建数据集指南)
  - [目录](#目录)
  - [项目介绍](#项目介绍)
  - [自建数据集通用流程](#自建数据集通用流程)
    - [1. 数据集格式需求确认](#1-数据集格式需求确认)
    - [2. 数据收集](#2-数据收集)
    - [3. 数据清洗与预处理](#3-数据清洗与预处理)
    - [4. 数据标注](#4-数据标注)
    - [5. 数据增强（可选）](#5-数据增强可选)
    - [6. 数据划分与存储](#6-数据划分与存储)
    - [7. 质量评估（必须）](#7-质量评估必须)
    - [8. 数据集发布与维护](#8-数据集发布与维护)
  - [案例分析：ChronoQA 数据集](#案例分析chronoqa-数据集)
    - [1. 数据源获取](#1-数据源获取)
    - [2. 数据预处理](#2-数据预处理)
    - [3. 问题生成与验证](#3-问题生成与验证)
    - [4. 数据集质量控制](#4-数据集质量控制)
    - [5. 结果存储](#5-结果存储)

---

## 项目介绍

数据集是模型训练的基础。然而，针对特定任务或领域，可能缺乏直接可用的数据集，因此需要自建数据集。本指南提供了一个系统化的流程，帮助大家从零开始构建高质量的数据集。

---

## 自建数据集通用流程

### 1. 数据集格式需求确认

在收集数据之前，首先需要确认数据集的格式需求，包括：

- **数据格式**：常见格式如 `JSON`、`CSV`、`Parquet`，根据任务需求选择合适的格式。
- **字段要求**：
  - 结构化数据：每条数据需要包含哪些字段？
  - 非结构化数据：如文本、图像、音频，是否需要额外的元数据？
- **存储方式**：
  - 是否存储在本地文件系统、数据库（如 MongoDB）、对象存储（如 S3）、或开源平台（如 Hugging Face）？
- **数据规模**：
  - 需要多少样本？如何保证数据的代表性？
- **使用场景**：
  - 是否用于训练、验证、测试？是否需要对数据进行版本控制？
- **数据隐私与合规性**：
  - 是否涉及敏感数据？是否需要去除个人身份信息（PII）？

在明确这些问题后，再进入下一步的数据收集。

---

### 2. 数据收集

数据收集是数据集构建的第一步，可采用以下几种方式：

- **公开数据集**：如 [Hugging Face Datasets](https://huggingface.co/datasets)、[Kaggle](https://www.kaggle.com/datasets)。
- **爬虫抓取**：从合法渠道获取数据，如新闻、社交媒体等（注意合规性）。
- **人工生成**：设计数据样本，适用于低资源任务。
- **LLM 生成**：使用 LLM 生成数据。
- **数据购买**：如果项目预算允许，可以申请购买第三方数据。

---

### 3. 数据清洗与预处理

- 统一数据格式（如 `.csv`、`.json`）。
- 去除无效样本（如乱码、重复数据）。
- 数据脱敏（如去除个人信息）。
- 规范化文本/图像/视频等数据（如分词、去除停用词、去噪）。
- 处理缺失值（插值、删除、填充）。

---

### 4. 数据标注

- **人工标注**：使用标注工具或者众包标注。
- **自动标注**：通过 LLM 或者其他模型进行自动化标注数据。
- **数据验证**：对于自动标注，需要人工验证可靠性。

---

### 5. 数据增强（可选）

- **文本数据**：同义词替换、回译（翻译再翻回）、文本拼接。
- **图像数据**：旋转、翻转、调整亮度、添加噪声。
- **语音数据**：音调变化、速度变化、背景噪音。

---

### 6. 数据划分与存储

- **划分比例**：通常按 80% 训练集，10% 验证集，10% 测试集。
- **存储格式**：`JSON`、`CSV`、`Parquet`、数据库等。

---

### 7. 质量评估（必须）

- **数据完整性检查**（是否有缺失值、格式错误）。
- **数据分布检查**（类别是否均衡）。
- **标注质量评估**（计算一致性指标，如 F1-score）。

---

### 8. 数据集发布与维护

- 通过 GitHub 或 Hugging Face 发布数据集，并定期更新数据集。
- 记录数据版本变更日志。
- 允许用户反馈数据错误并修正。

---

## 案例分析：ChronoQA 数据集

本部分以 ChronoQA 数据集为案例，介绍一个完整的时间敏感型 QA 数据集构建流程。

### 1. 数据源获取

ChronoQA 主要关注 **时间敏感型问题**，因此数据主要来自 **新闻**。其数据来源如下：

- **新闻文章收集**：使用爬虫抓取 2019-2024 年的新闻数据。
- **数据清洗**：去除重复、格式转换、时间标准化。

---

### 2. 数据预处理

- 选取具有时间信息的新闻段落，使用 LLM 生成简要的时间描述。
- 过滤掉没有明确时间标注的内容，确保数据的时间敏感性。

![爬取的段落数据集样例](./imgs/news.png)

---

### 3. 问题生成与验证

ChronoQA 采用以下流程构造问题集，结合了规则和LLM生成的方式：

- **单一时间问题生成**：撰写Prompt以及示例样本，让大模型依据具体段落生成单跳 QA 对，包括QA的对应label（自己拟定的类别等标签信息）。
- **多步推理问题构造**：结合规则和大模型，生成多跳QA对
  - **串联问题（series circuit）**：问题 1 依赖于问题 2 的答案。
  - **并联问题（parallel circuit）**：多个独立 QA 组合成更复杂的查询。
- **人工和自动化检查**：
  - 规则过滤（如时间冲突检测）。
  - LLM 评估问题质量。
  - 人工审核样本（确保 QA 质量）。

---

### 4. 数据集质量控制

- **多级过滤**：去除无效、低质量 QA 对。
- **统计分析**：
  - 时间范围覆盖：确保涵盖长短期时间推理任务。
  - 类别均衡性检查：避免过度偏向某些类别。

---

### 5. 结果存储

ChronoQA 数据最终以 **JSON 格式** 存储，包含以下字段：
```json
{
    "question":"2024年苹果计划的新款iPhone的目标出货量是多少？",
    "question_date":"2024-08-30",
    "answer":"至少9000万部",
    "temporal_expression_type":"implicit",
    "temporal_scope":"mid-term",
    "temporal_granularity":"year",
    "temporal_type":"absolute",
    "answer_type":"numerical",
    "reference_document_count":"single",
    "ref_prompt":"single_direct_expression",
    "reference_qa_list":null,
    "original_question":null,
    "event_name":null,
    "event_time":null,
    "golden_chunks":[
        "苹果计划在2024年新款iPhone出货量增长10%，目标出货量至少9000万部，预计这些目标将帮助公司在经历2023年困难后实现翻身。"
    ]
}
```
